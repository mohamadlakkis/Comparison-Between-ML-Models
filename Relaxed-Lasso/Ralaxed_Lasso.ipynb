{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training set and test set !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "SEED  = 0\n",
    "np.random.seed(SEED)\n",
    "def split_data():\n",
    "    DATA = pd.read_csv('prostate.data', sep='\\s+')\n",
    "    train_data = DATA[DATA.iloc[:, -1] == 'T'].values\n",
    "    test_data = DATA[DATA.iloc[:, -1] == 'F'].values\n",
    "    y_train = train_data[:, -2]\n",
    "    y_test = test_data[:, -2]\n",
    "    X_train = train_data[:, :-2]\n",
    "    X_test = test_data[:, :-2]\n",
    "    return X_train, X_test, y_train, y_test,DATA\n",
    "X_train, X_test, y_train,y_test,DATA = split_data()\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train) \n",
    "X_test_scaled = sc.transform(X_test)\n",
    "#We will use in CV, kfold with k = 5, since the data is small so 5 splits is better than 10 !\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED) # to make sure that when we use cross_validation the model is going to split them randomly, which cross_val_score doesn't do unless we specify the method we want like we are doing here !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step Lasso, and selecting the best $\\lambda$ for this model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49399783092864197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MIN_STEP_1 = np.inf\n",
    "MIN_LAMB_STEP_1 = None\n",
    "lambda_range = np.logspace(-10, 1, 100)\n",
    "for lamb in lambda_range:\n",
    "    lasso_model = Lasso(alpha=lamb,fit_intercept=True,random_state=SEED)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('lasso', lasso_model)])\n",
    "    SCORES_model = cross_val_score(pipeline, X_train, y_train, scoring='neg_mean_squared_error', cv=kfold) \n",
    "    SCORES_model = -SCORES_model\n",
    "    MEAN = SCORES_model.mean()\n",
    "    if MEAN<MIN_STEP_1:\n",
    "        MIN_STEP_1 = MEAN\n",
    "        MIN_LAMB_STEP_1 = lamb\n",
    "\n",
    "#notice that the best lambda is consistent with question 1(if we look at the CV criterion !)\n",
    "step_1_lasso_model = Lasso(alpha=MIN_LAMB_STEP_1, fit_intercept=True, random_state=SEED)\n",
    "step_1_lasso_model.fit(X_train_scaled, y_train)\n",
    "COEF_STEP_1 = step_1_lasso_model.coef_\n",
    "y_pred = step_1_lasso_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "INDEX_OF_ZERO = np.where(COEF_STEP_1 == 0)[0]\n",
    "## REMOVING THE INDECES OF ZERO FROM THE X_TRAIN_SCALED and X_TRAIN\n",
    "X_train_scaled_modified = np.delete(X_train_scaled, INDEX_OF_ZERO, axis=1) # Removing the columns in the INDEX_OF_ZERO\n",
    "X_train_modified = np.delete(X_train, INDEX_OF_ZERO, axis=1) # Removing the columns in the INDEX_OF_ZERO\n",
    "## REMOVING THE INDECES OF ZERO FROM THE X_TEST_SCALED and X_TEST\n",
    "X_test_scaled_modified = np.delete(X_test_scaled, INDEX_OF_ZERO, axis=1) # Removing the columns in the INDEX_OF_ZERO\n",
    "X_test_modified = np.delete(X_test, INDEX_OF_ZERO, axis=1) # Removing the columns in the INDEX_OF_ZERO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_STEP_2 = np.inf\n",
    "MIN_LAMB_STEP_2 = None\n",
    "lambda_range = np.logspace(-10, 0, 100)\n",
    "for lamb in lambda_range:\n",
    "    lasso_model = Lasso(alpha=lamb,fit_intercept=True,random_state=SEED)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('lasso', lasso_model)])\n",
    "    SCORES_model = cross_val_score(pipeline, X_train_modified, y_train, scoring='neg_mean_squared_error', cv=kfold) \n",
    "    SCORES_model = -SCORES_model\n",
    "    MEAN = SCORES_model.mean()\n",
    "    if MEAN<MIN_STEP_2:\n",
    "        MIN_STEP_2 = MEAN\n",
    "        MIN_LAMB_STEP_2 = lamb\n",
    "step_2_lasso_model = Lasso(alpha=MIN_LAMB_STEP_2, fit_intercept=True, random_state=SEED)\n",
    "step_2_lasso_model.fit(X_train_scaled_modified, y_train)\n",
    "COEF_STEP_2 = step_2_lasso_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between the Lambda_1 and Lambda_2 and the coef! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lambda 1 value =  0.012915496650148827, as for the lambda 2 value = 3.2745491628777316e-09\n",
      "So we can clearly see that the lambda 1 is bigger than the lambda 2, difference = 0.012915493375599664\n"
     ]
    }
   ],
   "source": [
    "print(f\"The lambda 1 value =  {MIN_LAMB_STEP_1}, as for the lambda 2 value = {MIN_LAMB_STEP_2}\")\n",
    "print(f\"So we can clearly see that the lambda 1 is bigger than the lambda 2, difference = {MIN_LAMB_STEP_1-MIN_LAMB_STEP_2}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict new Data we will create this function !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5165134813206721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def predict(X_NEW):\n",
    "    '''X_NEW should be full without any modification (i.e. without removing the variables from the first lasso the function does that automatically ), and unscaled !'''\n",
    "    X_NEW_scaled = sc.transform(X_NEW)\n",
    "    X_NEW_scaled_modified = np.delete(X_NEW_scaled, INDEX_OF_ZERO, axis=1) # removing the variables from the first Lasso \n",
    "    return step_2_lasso_model.predict(X_NEW_scaled_modified)\n",
    "\n",
    "'''getting the test error from our test data'''\n",
    "y_pred = predict(X_test)\n",
    "MSE_ERROR = mean_squared_error(y_test, y_pred)\n",
    "print(MSE_ERROR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
